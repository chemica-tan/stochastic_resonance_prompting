---
title: "「複数AIに同じプロンプトを投げて比較する」をツール化した — SRPスキルファイル公開"
emoji: "🎲"
type: "tech"
topics: ["AI", "LLM", "ClaudeCode", "プロンプトエンジニアリング"]
published: false
---

:::message
**この記事の要点**: 「同じプロンプトを複数AIに投げて比較する」は多くの人がやり始めています。SRP（Stochastic Resonance Prompting）はそれを方法論にしたもので、今回Claude Codeのカスタムスキルとして実装・公開しました。手動版（`/srp`、環境依存ゼロ）と自動版（`/quick-homo-srp`、Codex CLIで並列実行）の2つがあります。
:::

## はじめに — やっている人は増えている

最近、Xでこんなツイートを見かけました。

> claude と codex の両方に人力でお願いしてコードのレビューしてもらっていたので、4並列(Opus 4.6, Opus4.5, Codex 5.3, Codex 5.2) でレビュー or リファクタ提案をしてもらえるcommand作った
> — @634kami (2026-02-07)

同じタスクを複数のAIに投げて、結果を比較する。やってみると気づくことがあります——1つのモデルに聞いただけでは「他の選択肢があったこと自体」に気づけない。

でも、この行為には名前がありませんでした。「あー、俺もやってるよそれ」とは言えても、「それは〇〇という手法で、こういう原理で効くんだよ」とは言えない。名前がないと議論しにくい。

**Stochastic Resonance Prompting（SRP）** は、これに名前をつけて方法論にしたものです。そして今回、それを **Claude Codeのカスタムスキル** として実装しました。

この記事では:
1. SRPの思想を簡潔に紹介し
2. 手動版（`/srp`）と自動版（`/quick-homo-srp`）のスキルファイルを公開し
3. 設計上の工夫を解説します

スキルファイルの全文はGitHubで公開しています:
👉 **https://github.com/chemica-tan/stochastic_resonance_prompting**

---

## SRPとは何か

物理学に **確率共鳴（Stochastic Resonance）** という現象があります。微弱な信号にノイズを加えると、かえって信号が検出しやすくなる。直感に反する現象です。

SRPはこの着想をLLMプロンプティングに応用します。

**同じプロンプトを複数のAIに投げ、確率的にゆらぐ出力を比較することで、単一AIでは見えない構造を浮かび上がらせる。**

ここで大事なのは、SRPは「より良い答え」を直接出す手法では**ない**ということです。

- 4つのAIが全員同じことを言えば、それは強い合意
- 1つだけ違うことを言えば、それは検討に値する分岐点
- 合意が正しいこともあれば、たった1つの逸脱に本質が隠れていることもある
- 見極めるのは人間のドメイン知識

比較しなければ、選択があったこと自体に気づかない——これがSRPの核心です。

:::message
SRPの詳しい原理や実践例は[過去記事](#過去記事)で書いています。本記事は「ツールとして使えるもの」の公開がメインです。
:::

---

## `/srp` — 手動版

まず手動版から。**環境依存ゼロ**です。ChatGPT無料版でもGeminiでもClaudeでも使えます。

### どう動くか

Claude Codeのセッション中に `/srp` と打つと、今までの会話内容を分析して、他のAIに配布できる**自己完結型プロンプト**を生成します。セッション中の議論をプロンプトに「結晶化」するイメージです。

受け取るAI側はこのセッションの文脈を一切知らないので、必要な情報を全部プロンプトに詰め込む必要があります。それを手作業でやると大変ですが、`/srp` がやってくれます。

### 8セクション構成

生成されるSRPプロンプトは、こういう構造を持っています:

| セクション | 内容 | 共通/固有 |
|-----------|------|-----------|
| §1 Objective | タスクの目的 | 共通 |
| §2 Background | ドメイン知識・文脈 | 共通 |
| §3 Scope | やること・やらないこと | 共通 |
| §4 Constraints | 制約条件 | 共通 |
| §5 Input Materials | 読むべきファイル一覧 | 共通 |
| §6 Guiding Questions | 答えるべき質問リスト | 共通 |
| §7 Deliverable Spec | 成果物の仕様 | 共通 |
| §8 Output Instructions | 出力先・連番・モデル名 | **固有** |

**§1〜§7は全モデル共通、§8だけが異なります。** モデルごとにプロンプトをカスタマイズしない。これがSRPの大原則です。理由は後述します。

### ワンライナーで配布

プロンプトが生成されると、各AIに渡す用のワンライナーが出力されます:

```
#01 gpt_5.2:
srp_sessions/20260208_topic/20260208_topic_srp.md を読み、
そこに記載されたタスクを実行してください。
あなたの連番は 01、モデル名は gpt_5.2 です。

#02 gemini_3.0_pro:
srp_sessions/20260208_topic/20260208_topic_srp.md を読み、
そこに記載されたタスクを実行してください。
あなたの連番は 02、モデル名は gemini_3.0_pro です。

#03 claude_opus_4.6:
（以下同様）
```

これを各AIのインターフェースにコピペするだけ。ファイルシステムにアクセスできるコーディングエージェント（Claude Code, Codex CLI, Gemini Code Assist等）ならどれでも動きます。

---

## `/quick-homo-srp` — 自動版

ここまで読んで「いや手動で4回コピペはだるいだろ」と思った方、正しいです。

`/quick-homo-srp` は、SRPプロンプトの生成から並列実行までを自動化します。[Codex CLI](https://github.com/openai/codex)を使って、N個のインスタンスをバックグラウンドで同時に走らせます。

### 使い方

```
/quick-homo-srp calculator_redesign
```

これだけで:
1. セッションの議論からSRPプロンプトを生成
2. `gpt-5.2-codex` × 4インスタンスを並列起動
3. 各インスタンスの完了を監視して報告

モデルや本数は自然言語で変えられます:

```
/quick-homo-srp calculator_redesign codex 3つとgpt-5.2 1つ
/quick-homo-srp @existing_prompt.md gpt-5.2 x3
/quick-homo-srp 英語で calculator_redesign
```

### Generate mode と File mode

| モード | いつ使う | 起動方法 |
|--------|---------|---------|
| **Generate** | セッション中の議論をSRPにかけたい | `@` なしで普通に実行 |
| **File** | 既存のプロンプトを再利用したい | `@path/to/prompt.md` で指定 |

File modeが地味に便利です。「前回のSRPプロンプトを少し直して、もう1ラウンド回したい」というときに使います。

### 必要な環境

- **[Codex CLI](https://github.com/openai/codex)**: OpenAIのCLIツール
- **OpenAI APIキー**: 環境変数 `OPENAI_API_KEY` に設定済みであること

:::details 内部で実行されるコマンド
各インスタンスで以下が実行されます:

```bash
codex exec --full-auto \
  -C "/path/to/project" \
  -m gpt-5.2-codex \
  -c model_reasoning_effort="xhigh" \
  - <<'PROMPT_EOF'
[SRPプロンプト全文 + インスタンス固有の§8]
PROMPT_EOF
```

| オプション | 意味 |
|-----------|------|
| `exec` | 非インタラクティブモード |
| `--full-auto` | サンドボックス内で自動実行 |
| `-C` | 作業ディレクトリ |
| `-m` | モデル指定 |
| `-c model_reasoning_effort` | 推論レベル（`medium` / `high` / `xhigh`） |
| `-` | stdinからプロンプト読み込み |

`--full-auto` はサンドボックス内で全てのツール呼び出しを自動承認するモードです。SRPプロンプト内で「セッションフォルダにのみ書き込み、既存ファイルは変更しないこと」と制約しているので、安全に実行できます。
:::

---

## 設計思想 — 実運用で学んだこと

スキルファイルの設計には、実際にSRPを使い込む中で学んだ教訓が入っています。

### 1. Same prompt to all AIs

**モデルごとにプロンプトをカスタマイズしません。**

「GPTには詳しく、Claudeには簡潔に」みたいな調整をすると、出力の差が「モデルの個性」なのか「プロンプトの違い」なのか区別できなくなります。SRPの価値は確率的ゆらぎの比較にあるので、入力は統一します。

### 2. Thin-session guard

議論が薄いセッションでSRPを回すと、スカスカのプロンプトが4つ生成され、スカスカの出力が4つ返ってくるだけです。

スキルファイルには「§2 Backgroundをプロジェクト固有の内容で埋められないなら、ユーザーに警告する」ガードを入れました。**ゴミを4倍にしても金にはなりません。**

### 3. Free Commentary mandatory

§7の成果物仕様で、**Free Commentary（自由記述）を必須**にしています。

構造化された質問（§6）への回答だけだと、出力が収束しがちです。「問1にはこう答えるべき」というパターンにモデルがはまってしまう。自由記述を強制すると、「質問されていないけど気になったこと」を書く余地が生まれます。

実際、[前回の記事](https://zenn.dev/chemica_tan/articles/9e45560a8d3d6a)で発見した「437」の合意も、「設計上の欠陥」の指摘も、構造化回答ではなくFree Commentaryから出てきました。**ゆらぎが一番表出するのは自由記述部分です。**

### 4. Artifact Safety

SRPの出力は全てセッションフォルダに書きます。**プロダクションパスへの直接書き込みは禁止。**

4つのAIが同時にプロジェクトの同じファイルを上書きしたら大変なことになります。出力はセッションフォルダに隔離して、人間が監査してからプロダクションに移す。この手順は面倒に見えますが、事故が起きてから泣くよりずっと安いです。

### 5. アーティファクト命名規則

```
YYYYMMDD_{name}_{NN}_{MODEL_NAME}.{ext}
```

日付・連番（`NN`）・モデル名の3要素で、いつ・どのモデルが・何回目に作ったファイルかが一意に特定できます。同一モデルの複数回実行でも衝突しません。

---

## 導入方法

### 1. ファイルを配置

GitHubリポジトリからダウンロードして、Claude Codeプロジェクトの `.claude/skills/` に配置します:

```
.claude/skills/
├── srp/
│   ├── SKILL.md
│   └── commands/
│       └── srp.md
└── quick-homo-srp/        # 自動版が不要なら省略可
    ├── SKILL.md
    └── commands/
        └── quick-homo-srp.md
```

### 2. 再起動して実行

Claude Codeを再起動（またはセッションを新規開始）すれば、`/srp` や `/quick-homo-srp` がスラッシュコマンドとして認識されます。

### カスタマイズのポイント

| 項目 | デフォルト | 変更箇所 |
|------|-----------|---------|
| 出力パス | `srp_sessions/` | `commands/srp.md` 内のパス定義 |
| デフォルトモデル | `gpt-5.2-codex` x4 | `commands/quick-homo-srp.md` 内のデフォルト値 |
| 言語 | 日本語 | 各 `commands/*.md` 内の Language セクション |

自分のプロジェクト構造に合わせてパスを変えるのが一番ありがちなカスタマイズです。スキルファイル内を `srp_sessions` で検索して、好きなパスに書き換えてください。

スキルファイルの全文:
👉 **https://github.com/chemica-tan/stochastic_resonance_prompting**

---

## FAQ

**Q: 同じモデル × 4で多様性は出る？**

出ます。特に自由度の高いタスクでは十分出ます。[前回の記事](https://zenn.dev/chemica_tan/articles/9e45560a8d3d6a)では同一モデル4インスタンスから4つの異なる定義名、4つの異なる数式、4つの異なるTop 1が得られました。LLMの確率的生成が自然に多様性を担保します。

意図的に違うモデルを混ぜることもあります。ただ個人的な感触としては、**良いSRPプロンプトを用意できているかどうか**のほうが、モデルの選択よりも結果に効きます。

**Q: コスト4倍じゃない？**

並列実行なので所要時間は1回分とほぼ同じです。単独実行 → 不満 → やり直しを繰り返すより、最初から4回走らせるほうが効率的な場面は意外と多い。それに、2026年2月からCodexのレートリミットが2倍に引き上げられているので、試すにはいい時期です。

https://x.com/sama/status/2018437537103269909

**Q: 結果の統合は手動？**

はい、基本的には人間が読んで判断します。もちろん「4つのレポートを読んで統合レポートを作って」とAIに頼むこともできますが、ドメイン判断が入る統合は人間が介入したほうがいい。というか、比較結果を見ると介入**したくなる**と思います。

**Q: どんなタスクに向いている？**

正解がないオープンエンドなタスクです。設計レビュー、リファクタリング方針、仕様書の策定、計画の立案。逆に、ソートや計算のような決定論的タスクには無駄です。

私の場合、化学工学の論文に書かれた原子の組み合わせルールをSMARTS（分子構造のパターン記法）に変換する作業で多用しています。「仕様は自然言語で書いてあるが、変換の正しさは厳密に検証する必要がある」タイプのタスクにSRPは向いています。

**Q: Claude Code以外でも使える？**

`/srp`（手動版）が生成するのはただのマークダウンファイルです。コピペすればどのAIでも使えます。前回のnote記事は全部手動コピペでやりました。`/quick-homo-srp`（自動版）はCodex CLIに依存しますが、原理的にはどのCLIツールでも同じことができます。

---

## 過去記事

SRPの初出と実践例:

1. **[note] [Stochastic Resonance Prompting: 初心者でも1550行→950行、50分で実現したAI協働リファクタリング手法](https://note.com/chemica_tan/n/n92f4ee61a831)**（2025年6月）— SRPの初出。R初心者がAI4つと協働してリファクタリングした話
2. **[Zenn] [同じプロンプトを4つのAIに投げたら、1つだけでは見えない答えが見えた — SRP実践録](https://zenn.dev/chemica_tan/articles/9e45560a8d3d6a)**（2026年2月）— 「グロタンディーク素数らしさ」タスクで合意と分岐を観察した話

---

## おわりに

「複数AIに同じプロンプトを投げて比較する」は、すでに多くの人がやっています。

SRPはそれに名前をつけ、方法論として定式化し、今回ツールにしました。

**名前があると議論できる。ツールがあると再現できる。**

使ってみて気づいたことがあれば、ぜひコメントで教えてください。SRPは「こうすべき」という完成された手法ではなく、「こうしたら面白かった」を共有するためのフレームワークです。
